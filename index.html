<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Pick-n-Place</title>
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Bootstrap -->
    <link rel="stylesheet" type="text/css"  href="css/bootstrap.css">
    <link rel="stylesheet" type="text/css" href="fonts/font-awesome/css/font-awesome.css">

    <!-- Stylesheet
        ================================================== -->
    <link rel="stylesheet" type="text/css"  href="css/style.css">
    <link rel="stylesheet" type="text/css" href="css/prettyPhoto.css">
     <!-- <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700,800,600,300' rel='stylesheet' type='text/css'>-->
     <!-- <script type="text/javascript" src="js/modernizr.custom.js"></script>-->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->
</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
	<div id="preloader">
		<div id="status"> <img src="img/preloader.gif" height="64" width="64" alt=""> </div>
	</div>
	
	
	<!-- Navigation -->
	<nav class="navbar navbar-custom navbar-fixed-top" role="navigation">
		<div class="container">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse"> <i class="fa fa-bars"></i> </button>
				<a class="navbar-brand page-scroll" href="#page-top"> <i class="fa fa-paper-plane-o"></i>Reasoning Pose-aware Placements with Semantic Labels - Brandname-based Affordance Prediction and Cooperative Dual-Arm Active Manipulation</a> 
			</div>
			
			<!-- Collect the nav links, forms, and other content for toggling -->
			<div class="collapse navbar-collapse navbar-right navbar-main-collapse">
				<ul class="nav navbar-nav">
					<!-- Hidden li included to remove active class from about link when scrolled up past about section -->
					<li class="hidden"> <a href="#page-top"></a> </li>
					<li> <a class="page-scroll" href="#about">About</a> </li>
					<li> <a class="page-scroll" href="#development">Development</a> </li>
					<li> <a class="page-scroll" href="#code">code</a> </li>
					<li> <a class="page-scroll" href="#dataset">Dataset</a> </li>
					<!-- <li> <a class="page-scroll" href="#works">Portfolio</a> </li> -->
					<li> <a class="page-scroll" href="#team">Team</a> </li>
					<!-- <li> <a class="page-scroll" href="#sponsor">Sponsor</a> </li> -->
					<!-- <li> <a class="page-scroll" href="#schedule">Schedule</a> </li> -->
					<!-- <li> <a class="page-scroll" href="#testimonials">Testimonials</a> </li> -->
					<li> <a class="page-scroll" href="#contact">Contact</a> </li>
				</ul>
			</div> <!-- /.navbar-collapse --> 
		</div> <!-- /.container --> 
	</nav>


	<!-- Header -->
	<div id="intro">
		<div class="intro-body">
			<div class="container">
				<div class="row">
					<div class="col-md-10 col-md-offset-1">
						<h1><p style="font-size: 34pt;">Reasoning Pose-aware Placements with Semantic Labels - Brandname-based Affordance Prediction and Cooperative Dual-Arm Active Manipulation</h1>
						<!-- <p class="intro-text">National Chiao Tung University, Taiwan</p> -->
						<!-- <span class="brand-heading">Robotic Vision 2018 Syllabus</span></h1> -->
						<!-- <p class="intro-text">A full-service digital agency that loves what we do</p> -->
						<a href="#about" class="btn btn-default page-scroll">More Information</a> 
					</div>
				</div>
			</div>
		</div>
	</div>


	<!-- About Section -->
	<div id="about">
		<div class="container">
			<div class="section-title text-center center">
				<h2>About us</h2>
				<hr>
			</div>
			<div class="row">
				<div class="col">
					<div class="about-text text-center center">
						<iframe width="560" height="315" src="https://www.youtube.com/embed/TBb5fs_wuLg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
					</div>
				</div>
				<!-- <div class="col-md-4"><img src="img/about.jpg" class="img-responsive"></div> -->
				<div class="col">
					<div class="about-text">
						<h4>Abstract: </h4>
						<p style="font-size: 16pt; text-align: justify;">  The Amazon Picking/Robotics Challenges showed significant progress in object picking from a cluttered scene, yet object placing remains challenging. Pose-aware placing based on human and machine readable pieces on an object is useful. For example, the brandname of an object placed on a shelf should be facing the human customers. Similarly, the barcode of an object placed on a conveyer should be facing a machine scanner. There are robotic vision challenges in the object placing task: a) the semantics and geometry of the object to be placed need to be analysed jointly; b) and the occlusions among objects in a cluttered scene could make it hard for proper understanding and manipulation. To overcome these challenges, we develop a pose-aware placing system by spotting the semantic labels (e.g., brandnames) of objects in a cluttered tote, and then carrying out a sequence of actions to place the objects on a shelf or a conveyor with desired poses. Our major contributions include 1) providing an open benchmark dataset of objects, brandnames, and barcodes with multi-view segmentation for training and evaluations; 2) carrying out comprehensive evaluations for our brandname-based fully convolutional network (FCN) that can predict affordance and grasp to achieve pose-aware placing, whose success rates decrease along with clutters; 3) showing that active manipulation with two cooperative manipulators and grippers can effectively handle occlusions of brandnames. We analyzed the success rates and discussed the failure cases to provide insights for future applications. </p>
					</div>
				</div>

				<!--div class="col-md-2"><center><img src="img/sensor.jpg" class="img-responsive"></center></div-->
			</div>
		</div>
	</div>

	<!-- Development Section -->
	<div id="development">
		<div class="container">
			<div class="section-title text-center center">
				<h2>		
					<p style="color:Orange;text-align:center;font-size: 22pt;">
						Development
					</p>
				</h2>
				<hr>
			</div>

			<div class="row">
				<div class="col-md-5">
					<center><img src="img/paperimg/robot_system_v1.png" class="img-responsive"></center>
				</div>
				<div class="col-md-7">
					<div class="about-text">
						<p style="color:white;text-align:left;font-size: 25pt;"><strong>Robot System</strong></p>
					</div>
					<p style="text-align:left;font-size: 16pt;">
						<strong>Collaborative robotic system:</strong> we propose a dual-arm cooperative system to actively manipulate the scene to improve perception for placing. The gripper arm moves an occluding object to reveal information (the invisible brandname) hidden underneath, and the two-finger arm further predicts grasp using the brandname and completes pose-aware placing.
				</div>
			</div>
			
			<br>
            <br>

			<div class="row">
				<div class="col-md-5">
					<center><img src="img/paperimg/text-pose-extimation-pipeline.png" class="img-responsive">
					</center>
				</div>
				<div class="col-md-7">
					<div class="about-text">
						<p style="color:white;text-align:left;font-size: 25pt;"><strong>Brandname Prediction</strong></p>
						<p style="text-align:left;font-size: 16pt;">
							In real scenario, the text angle could be 0 360 degree. To make the vision system detect text as much as possible without moving the robot arm. The image from SR300 is rotated at 0, 90, 180, 270, and then converted to gray images which are used as inputs as FCN model. Then each connected segmented text is bounded by a rotated box. Finally, these prediction results are rotated and combined as a final prediction mask which is used for 6D text pose estimation.
						</p>
					</div>
				</div>
			</div>

			<br>
            <br>

			<div class="row">
				<div class="col-md-5">
					<center><img src="img/paperimg/bn-benchmark-dataset.png" class="img-responsive"></center>
				</div>
				<div class="col-md-7">
					<div class="about-text">
						<p style="color:white;text-align:left;font-size: 25pt;"><strong>Virtual Data Generator</strong></p>
						<p style="text-align:left;font-size: 16pt;">
							<strong>Data collection in virtual environment: </strong>
							Data collection of training data in real (left) and virtual (right) environments. Upper-left: Samples of objects and their brandnames (red polygons). Top-right: creating an object model via the 3D builder in Unity. Each scene contains only one object, given the findings that batch-training with a single object could yield deep models that perform good inference results on scenes with multiple objects.
							 <!-- To efficiently collect and label data, a virtual environment is built up. There are four cameras in virtual environment automatically collecting different data: RGB image, depth image, object mask, brand name mask, and barcode mask. In the virtual environment, object and camera can be placed anywhere without robot arm, so data collection tasks can be executed fast. -->
						</p>
					</div>
				</div>
			</div>
		</div>
	</div>
	
	<!-- Contact Section -->
	<div id="code" class="text-center">
		<div class="container">
			<div class="section-title center">
				<h2>Code</h2>
				<hr>
				 <p style="font-size: 14pt;"> It will be released soon. </p>
				<!-- <p style="font-size: 14pt;">If you are interested in our system, please visit our Github repo <a href="https://github.com/ARG-NCTU/text-pick-and-place-system">Github repo</a></p> -->
			</div>

		</div>
	</div>

	<div id="dataset" class="text-center">
		<div class="container">
			<div class="section-title center">
				<h2>Dataset</h2>
				<hr>
				<p style="font-size: 14pt; text-align: justify;"> Our paper references three datasets (all of them available for download):
		        <br>
		        <br>
		        &nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp;&nbsp;<a href="#real-brandname-object-segmentation-dataset">Real Training Dataset for brandname and object segmentation</a>
		        <br>
		        &nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp;&nbsp;<a href="#virtual-brandname-object-segmentation-dataset">Virtual Training Dataset for brandname and object segmentation</a>
		        <br>
		        &nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp;&nbsp;<a href="#benchmark-brandname-object-dataset">Benchmark Dataset for brandname and object segmentation</a>
		        <br>
		        <br>

				<br>
				<br>
				Our training dataset has two collections:
				1) the one from real environment and robot includes image variences of the illumination changes, object reflectiveness, and different tint. 2) An virtual environment similar to the
				real environment settings for comparisons.

				
		        In terms of file structure, the RGB-D camera sequence for each scene is saved into a corresponding folder by its name (‘scene_000000’, ‘scene_000001’, etc.).<!--  The folder contents are as follows: -->
		        <br>
		    	<br>
		    </p>


				</p>
			</div>

			<div class="section-title center">
				<h2 id="real-brandname-object-segmentation-dataset">Real Brandname and Object Segmentation Dataset</h2>
        		<br>
        		<p style="font-size: 14pt;text-align: justify;">
     			   Real Brandname and Object Segmentation Dataset Download: <a href="https://drive.google.com/open?id=1GVZGGW7sZ9bYNpv1m1t3IVZhPVE3nf8U">real_data.tar.gz (4 GB)</a>
     			<br>
     			<br>

     			   We select 20 products in our dataset, and the selection is based on the following criteria: 1) the physical height of brandname region is larger than 1.5 centimeters, 2) single line brandname, and 3) the brandname instance only occurs once on the object. There are 46 scenes × 31 views × 20 objects, resulting in 28,520 images. Among them, there are 26 scenes, total 16,120 images, including brandname label. The folder contents are as follows:
     			   <br><br>
     			</p>

     			<div class="col-md-12">
		    	<p style="font-size: 18pt; text-align: justify;">

		    	<strong>img/(object_name)</strong>
		    	</p>
		          <div id="text-tab">

		          	<p style="font-size: 14pt; text-align: justify;">
		          	&bull;&nbsp;<strong>XXXXXX.jpg</strong> - a 24-bit JPEG RGB color image captured from the Realsense camera.
		          </p>
		          </div>
		         

		      </div>

     			<div class="col-md-12">
		    	<p style="font-size: 18pt; text-align: justify;">

		    	<strong>mask/(object_name)</strong>
		    	</p>

		          <div id="text-tab">

		          	<p style="font-size: 14pt; text-align: justify;">
		          	&bull;&nbsp;<strong>XXXXXX.png</strong> - 8-bit PNG image of ground truth brandname and object segmentation labels using the annotation tool LabelMe. The pixel would be 255 if it is a object, 0 if not.
		          </p>
		          	<br>
		    		<br> 
		          </div>

		        </div>

     			<br>
     			
     			<br>
     			<br>
				<div class="row">
				  <div class="col">
				  	<img src="img/real/1.jpg"  width="15%">
				  	<img src="img/real/2.jpg"  width="15%">
				  	<img src="img/real/3.jpg"  width="15%">
				  	<img src="img/real/4.jpg"  width="15%">
				  	<img src="img/real/5.jpg"  width="15%">
				  	<img src="img/real/6.jpg"  width="15%">
				  </div>
				  <div class="col">
				  	<img src="img/real/1.png"  width="15%">
				  	<img src="img/real/2.png"  width="15%">
				  	<img src="img/real/3.png"  width="15%">
				  	<img src="img/real/4.png"  width="15%">
				  	<img src="img/real/5.png"  width="15%">
				  	<img src="img/real/6.png"  width="15%">				  	
				  </div>
				  <div class="col">
				  	<img src="img/real/7.jpg"  width="15%">
				  	<img src="img/real/8.jpg"  width="15%">
				  	<img src="img/real/9.jpg"  width="15%">	
				  	<img src="img/real/10.jpg"  width="15%">
				  	<img src="img/real/11.jpg"  width="15%">
				  	<img src="img/real/12.jpg"  width="15%">
				  </div>			
				  <div class="col">
				  	<img src="img/real/7.png"  width="15%">
				  	<img src="img/real/8.png"  width="15%">
				  	<img src="img/real/9.png"  width="15%">	
				  	<img src="img/real/10.png"  width="15%">
				  	<img src="img/real/11.png"  width="15%">
				  	<img src="img/real/12.png"  width="15%">
				  </div>		  				  				  
				</div>
     		</div>

		    <br>
		    <br>


			<div class="section-title center">
				<h2 id="virtual-brandname-object-segmentation-dataset">Virtual Brandname and Object Segmentation Dataset</h2>
        		<br>
        		<p style="font-size: 14pt;text-align: justify;">
<!--         			
        			Virtual Object Segmentation Dataset Download: <a href="https://drive.google.com/open?id=1pTHBihOfWR0EIXRLpNak4PWj2KUc7AZO">virtual_object.tar.gz (17 GB)</a>
        			<br> -->
     			    Virtual Brandname Segmentation Dataset Download: <a href="https://drive.google.com/open?id=12mLjojKKRuTTzThha4JaVfLbZIG7qf5D">virtual_brandname.tar.gz (6 GB)</a>
     			</p>
     			<br>
     			<br>
     			<p style="font-size: 14pt; text-align: justify;">
     			   1) Objects: For object-oriented dataset, due to the differ- ent shape of the object, there are 3 kinds of placing strategy and number of scene. The dataset have cylinder (8 objects): 116 scenes, cuboid (10 bjects): 108 scenes, rounded cuboid (2 objects): 72 scenes, totally 2152 scenes × 15 views × 4 modes of adding noise, resulting in 129,120 images.
     			   <br>
     			   2) Brandnames: The brandname-oriented dataset has 20 objects × 10 scenes × 54 views × 4 modes of adding noise, resulting in 43,200 images. Among them, there are 24,624 images including brandname label and 16,508 images including barcode label.
				</p>
     			<br>
     			<br>

     			<div class="col-md-12">
		    	<p style="font-size: 18pt; text-align: justify;">

		    	<strong>(object_name)/Scene</strong>
		    	</p>
		          <div id="text-tab">

		          	<p style="font-size: 14pt; text-align: justify;">
		          	&bull;&nbsp;<strong>X_original.png</strong> - a 24-bit PNG RGB color image captured from unity's virtual camera.
		          </p>
		          </div>
		          <div id="text-tab">
		          	<p style="font-size: 14pt; text-align: justify;">
		          	&bull;&nbsp;<strong>X_label.png</strong> - 8-bit PNG image of ground truth brandname and barcode segmentation labels. The pixel would be 255 in value if it is brandname, and barcode in 128.
		          	</p>
		          </div>
		     	  <!--div id="text-tab">
		          	<p style="font-size: 14pt; text-align: justify;">
		          	&bull;&nbsp;<strong>X_depth.png</strong> - a 24-bit PNG register depth image captured from the Realsense camera, aligned to its corresponding color image. Depth is saved in deci-millimeters (10-4m).
		          	</p>
		          </div-->     
		          <div id="text-tab">
		          	<p style="font-size: 14pt; text-align: justify;">
		          	&bull;&nbsp;<strong>X_seg.png</strong> - a 24-bit PNG RGB color image regarded as ground truth object segmentation labels. The pixel would be red if it is an object, green if it is tote, blue if it is out of tote (background).
		          	<br><br>
		          </p>
		          
		          </div>

		      </div>


				<div class="row">
				  <div class="col">
				  	<img src="img/virtual/1_1.png"  width="15%">
				  	<img src="img/virtual/2_1.png"  width="15%">
				  	<img src="img/virtual/3_1.png"  width="15%">
				  	<img src="img/virtual/4_1.png"  width="15%">
				  	<img src="img/virtual/5_1.png"  width="15%">
				  	<img src="img/virtual/6_1.png"  width="15%">
				  </div>
				  <div class="col">
				  	<img src="img/virtual/1_2.png"  width="15%">
				  	<img src="img/virtual/2_2.png"  width="15%">
				  	<img src="img/virtual/3_2.png"  width="15%">
				  	<img src="img/virtual/4_2.png"  width="15%">
				  	<img src="img/virtual/5_2.png"  width="15%">
				  	<img src="img/virtual/6_2.png"  width="15%">			  	
				  </div>
				  <div class="col">
				  	<img src="img/virtual/1_3.png"  width="15%">
				  	<img src="img/virtual/2_3.png"  width="15%">
				  	<img src="img/virtual/3_3.png"  width="15%">
				  	<img src="img/virtual/4_3.png"  width="15%">
				  	<img src="img/virtual/5_3.png"  width="15%">
				  	<img src="img/virtual/6_3.png"  width="15%">
				  </div>			
				  <div class="col">
				  	<img src="img/virtual/1_4.png"  width="15%">
				  	<img src="img/virtual/2_4.png"  width="15%">
				  	<img src="img/virtual/3_4.png"  width="15%">
				  	<img src="img/virtual/4_4.png"  width="15%">
				  	<img src="img/virtual/5_4.png"  width="15%">
				  	<img src="img/virtual/6_4.png"  width="15%">
				  </div>		  				  				  
				</div>

     		</div>

		    <br>
		    <br>

			<div class="section-title center">
				<h2 id="benchmark-brandname-object-dataset">Benchmark Brandname and Object Dataset</h2>
        		<br>
        		<p style="font-size: 14pt; text-align: justify;">
     			   Benchmark Brandname and Object Segmentation Dataset Download: <a href="https://drive.google.com/open?id=1CtAz1fnFKYMWPC7_oraeuNZWZhEX2r80"> benchmark (203 MB)</a></p>
     			<br>
     			<br>
     			<p style="font-size: 14pt; text-align: justify;">
     				There are six kinds of benchmark dataset for object and brandname separately, and all of them are seen from SR300 camera’s viewpoints during experiment. All the scenes were captured in our lab environment (at NCTU), with strong overhead directional lights. In total, there are 1010 images with manually annotated ground truth segmentation labels.
					Each scene (in addition to the files described here), contains: 
					<br>
					<br>

		          	&bull;&nbsp;<strong>img/X_obj/scene-XXXXXX</strong> - a 24-bit JPEG RGB color image captured from the Realsense camera.
					<br>
					&bull;&nbsp;<strong>mask/X_obj/scene-XXXXXX</strong> - 8-bit PNG image of ground truth object segmentation labels using the annotation tool LabelMe. Divide each pixel value by 12 to obtain label range [0,21].     			

     			<br>
     			<br>     			
     			</p>
				<div class="row">
				  <div class="col">
				  	<img src="img/benchmark/1.jpg"  width="15%">
				  	<img src="img/benchmark/2.jpg"  width="15%">
				  	<img src="img/benchmark/3.jpg"  width="15%">
				  	<img src="img/benchmark/4.jpg"  width="15%">
				  	<img src="img/benchmark/5.jpg"  width="15%">
				  	<img src="img/benchmark/6.jpg"  width="15%">
				  </div>
				  <div class="col">
				  	<img src="img/benchmark/1.png"  width="15%">
				  	<img src="img/benchmark/2.png"  width="15%">
				  	<img src="img/benchmark/3.png"  width="15%">
				  	<img src="img/benchmark/4.png"  width="15%">
				  	<img src="img/benchmark/5.png"  width="15%">
				  	<img src="img/benchmark/6.png"  width="15%">				  	
				  </div>
				  <div class="col">
				  	<img src="img/benchmark/13.jpg"  width="15%">
				  	<img src="img/benchmark/17.jpg"  width="15%">
				  	<img src="img/benchmark/18.jpg"  width="15%">	
				  	<img src="img/benchmark/9.jpg"  width="15%">
				  	<img src="img/benchmark/11.jpg"  width="15%">
				  	<img src="img/benchmark/12.jpg"  width="15%">
				  </div>			
				  <div class="col">
				  	<img src="img/benchmark/13.png"  width="15%">
				  	<img src="img/benchmark/17.png"  width="15%">
				  	<img src="img/benchmark/18.png"  width="15%">	
				  	<img src="img/benchmark/9.png"  width="15%">
				  	<img src="img/benchmark/11.png"  width="15%">
				  	<img src="img/benchmark/12.png"  width="15%">
				  </div>		  				  				  
				</div>
     		</div>
		    <br>
		    <br>
		</div>
	</div>	
	
	<div id="team" class="text-center">
		<!-- Prof Section -->
<!-- 		<div class="container">
			<div class="section-title center">
				<h2>Advisors</h2>
				<hr>
			</div>
			
			<div id="row">
				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail"> <img src="img/team/nick_wang.jpg" alt="..." class="img-thumbnail team-img">
						<div class="caption">
							<h3>Prof. Hsueh-Cheng 'Nick' Wang</h3>
							<p>Department of Electrical and Computer Engineering, NCTU</p>
							
						</div>
					</div>
				</div>
			</div> 
			 

		</div>  -->
		
		<!-- Students Section -->
		<div class="container">
			<div class="section-title center">
				<h2>Team Members</h2>
				<hr>
			</div>

			<div class="row">
				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail" > <img src="img/team/michael_smile1.jpg"  alt="..." class="img-thumbnail team-img" >
						<div class="caption">
							<h3>Yung-Shang 'Michael' Su</h3>
							<p>Department of Electrical and Computer Engineering, NCTU, Team Lead</p>
						</div>
					</div>
				</div>

				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail"> <img src="img/team/sean1.jpg" alt="..." class="img-thumbnail team-img">
						<div class="caption">
							<h3>Shao-Huang 'Sean' Lu</h3>
							<p>Department of Electrical and Computer Engineering, NCTU</p>
						</div>
					</div>
				</div>
                <div class="col-md-3 col-xs-6  col-sm-6" style="height: 400px;">
					<div class="thumbnail"> <img src="img/team/AndySer1.jpg" alt="..." class="img-thumbnail team-img">
						<div class="caption">
							<h3>Po-Sheng 'Andy' Ser</h3>
							<p>Department of Electrical and Computer Engineering, NCTU</p>
						</div>
					</div>
				</div>
				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail"> <img src="img/team/lily1.jpg" alt="..." class="img-thumbnail team-img">
						<div class="caption">
							<h3>Wei-Ting 'Lily' Hsu</h3>
							<p>Department of Electrical and Computer Engineering, NCTU</p>
						</div>
					</div>
				</div>
				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail"> <img src="img/team/lai1.jpg" alt="..." class="img-thumbnail team-img">
						<div class="caption">
							<h3>Wei-Cheng 'Sean' Lai</h3>
							<p>Department of Electrical and Computer Engineering, NCTU</p>
						</div>
					</div>
				</div>

				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail"> <img src="img/team/Biao_Xie.jpg" alt="..." class="img-thumbnail team-img">
						<div class="caption">
							<h3>Biao Xie</h3>
							<p>Department of Computer Science, University of Massachusetts at Boston, USA</p>
						</div>
					</div>
				</div>

				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail"> <img src="img/team/peterx1.jpg" alt="..." class="img-thumbnail team-img">
						<div class="caption">
							<h3>Hung-Ming 'Peter' Huang</h3>
							<p>Department of Electrical and Computer Engineering, NCTU</p>
						</div>
					</div>
				</div>
				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail" > <img src="img/team/Lee1.jpg"  alt="..." class="img-thumbnail team-img" >
						<div class="caption">
							<h3>Teng-Yok Lee</h3>
							<p>Mitsubishi Electric Research Laboratories, Cambridge, MA, USA</p>
						</div>
					</div>
				</div>

				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail" > <img src="img/team/.jpg"  alt="..." class="img-thumbnail team-img" >
						<div class="caption">
							<h3>Hung-Wen Chen</h3>
							<p>Delta Research Center, Taiwan</p>
						</div>
					</div>
				</div>



				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail"> <img src="img/team/pro_small1.jpg" alt="..." class="img-thumbnail team-img">
						<div class="caption">
							<h3>Prof. Lap-Fai 'Craig' Yu</h3>
							<p>Department of Computer Science, George Mason University</p>
						</div>
					</div>
				</div>
				<div class="col-md-3 col-xs-6 col-sm-6" style="height: 400px;">
					<div class="thumbnail"> <img src="img/team/nick_wang.jpg" alt="..." class="img-thumbnail team-img">
						<div class="caption">
							<h3>Prof. Hsueh-Cheng 'Nick' Wang</h3>
							<p>Department of Electrical and Computer Engineering, NCTU</p>
						</div>
					</div>
				</div>
			</div>
		</div> <!-- container -->
	</div>
	



	<!-- Sponsor Section -->
<!-- 	<div id="sponsor" class="text-center">
		<div class="container">
			<div class="section-title center">
				<h2>Sponsor</h2>
				<hr>
			</div>

			<div id="row">
				<div class="col-md-6 col-xs-6"">
					<div class="thumbnail"> <img src="img/sponsor/logo_ncsist.jpg" alt="..." class="img-responsive team-img">
						<div class="caption">
							<h3>National Chung-Shan Institute of Science &amp; Technology</h3>
						</div>
					</div>
				</div>
				<div class="col-md-6 col-xs-6">
					<div class="thumbnail"> <img src="img/sponsor/logo_nctu_ece.jpg" alt="..." class="img-responsive team-img">
						<div class="caption">
							<h3>National Chiao Tung University College of Electrical and Computer Engineering</h3>
						</div>
					</div>
				</div>

				<div class="col-md-12 col-xs-12">
					<div class="thumbnail"> <img src="img/sponsor/logo_most.jpg" alt="..." class="img-responsive  team-img">
						<div class="caption">
							<h3>Ministry of Science and Technology</h3>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>
 -->

	<!-- Contact Section -->
	<div id="contact" class="text-center">
		<div class="container">
			<div class="section-title center">
				<h2>Contact us</h2>
				<hr>
				<p style="font-size: 14pt;">If you are interested, please visit our <a href="https://arg-nctu.github.io">ARG-NCTU website</a> or contact us with following information.</p>
			</div>
			<div class="col-md-8 col-md-offset-2">
				<div class="col-md-6">
					<div class="contact-item"> <i class="fa fa-map-marker fa-2x"></i>
						<p style="font-size: 12pt;">(EE627)1001 University Road, Hsinchu,<br>
						Taiwan 30010, ROC</p>
					</div>
				</div>
				<div class="col-md-6">
					<div class="contact-item"> <i class="fa fa-envelope-o fa-2x"></i>
						<p style="font-size: 12pt;">Yung-Shan Su</p>
						<p style="font-size: 12pt;">michael1994822@gmail.com</p>
					</div>
				</div>
				<div class="clearfix"></div>
			</div>
		</div>
	</div>



	<div id="footer">
		<div class="container">
			<p>Copyright &copy; Modus. Designed by <a href="http://www.templatewire.com" rel="nofollow">TemplateWire</a></p>
		</div>
	</div>

	<!-- jQuery (necessary for Bootstrap's JavaScript plugins) --> 
	<script type="text/javascript" src="js/jquery.1.11.1.js"></script> 
	<!-- Include all compiled plugins (below), or include individual files as needed --> 
	<script type="text/javascript" src="js/bootstrap.js"></script> 
	<script type="text/javascript" src="js/SmoothScroll.js"></script> 
	<script type="text/javascript" src="js/jquery.prettyPhoto.js"></script> 
	<!-- <script type="text/javascript" src="js/jquery.isotope.js"></script> -->
	<!-- <script type="text/javascript" src="js/jquery.parallax.js"></script> -->
	<script type="text/javascript" src="js/jqBootstrapValidation.js"></script> 
	<!-- <script type="text/javascript" src="js/contact_me.js"></script> -->

	<!-- Javascripts
		================================================== --> 
	<script type="text/javascript" src="js/main.js"></script>
</body>
</html>
